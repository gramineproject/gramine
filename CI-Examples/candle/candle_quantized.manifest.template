# Copyright (C) 2024 Gramine contributors
# SPDX-License-Identifier: BSD-3-Clause

libos.entrypoint = "/candle_quantized"

loader.log_level = "{{ log_level }}"

loader.env.LD_LIBRARY_PATH = "/lib:{{ arch_libdir }}"
loader.env.RAYON_NUM_THREADS = { passthrough = true }

loader.argv = [ "candle_quantized", "--model", "llama-2-7b.ggmlv3.q4_0.bin",
                "--tokenizer", "tokenizer.json", "--sample-len", "200" ]

fs.mounts = [
  { path = "/candle_quantized", uri = "file:candle_quantized" },
  { path = "/lib", uri = "file:{{ gramine.runtimedir() }}" },
  { path = "{{ arch_libdir }}", uri = "file:{{ arch_libdir }}" },

  { path = "/llama-2-7b.ggmlv3.q4_0.bin", uri = "file:llama-2-7b.ggmlv3.q4_0.bin" },
  { path = "/tokenizer.json", uri = "file:tokenizer.json" },
]

sgx.debug = true
sgx.edmm_enable = {{ 'true' if env.get('EDMM', '0') == '1' else 'false' }}
sgx.max_threads = {{ '1' if env.get('EDMM', '0') == '1' else '256' }}
sgx.enclave_size = "32G"

sgx.trusted_files = [
  "file:candle_quantized",
  "file:{{ gramine.runtimedir() }}/",
  "file:{{ arch_libdir }}/libcrypto.so.3",
  "file:{{ arch_libdir }}/libgcc_s.so.1",
  "file:{{ arch_libdir }}/libssl.so.3",

  "file:llama-2-7b.ggmlv3.q4_0.bin",
  "file:tokenizer.json",
]
